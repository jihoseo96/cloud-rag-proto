# app/services/indexer.py
import uuid
from typing import Optional
from sqlalchemy.orm import Session
from app.services.s3 import get_pdf_bytes
from .extract import extract_text_pages
from .chunker import chunk_pages
from .embed import embed_texts
from app.models.chunk import Chunk

def index_document(
    db: Session,
    doc_id,            # uuid.UUID ê¶Œì¥
    s3_key: str,
    title: str,
    pdf_bytes: Optional[bytes] = None,
) -> int:
    """
    ì£¼ì–´ì§„ documentì— ëŒ€í•´ ì¸ë±ì‹±(ë˜ëŠ” ì¬ì¸ë±ì‹±)ì„ ìˆ˜í–‰í•œë‹¤.

    - pdf_bytesê°€ ì£¼ì–´ì§€ë©´ ê·¸ ë°”ì´íŠ¸ë¥¼ ì‚¬ìš©í•˜ê³ ,
      ì—†ìœ¼ë©´ s3_key ê¸°ì¤€ìœ¼ë¡œ S3ì—ì„œ íŒŒì¼ì„ ì½ì–´ì˜¨ë‹¤.
    - í•­ìƒ ê¸°ì¡´ Chunkë¥¼ ì‹¹ ì§€ìš´ ë’¤ ìƒˆë¡œ ìƒì„±í•˜ë¯€ë¡œ,
      ì—¬ëŸ¬ ë²ˆ í˜¸ì¶œí•´ë„ ì¤‘ë³µ ì²­í¬ê°€ ìƒê¸°ì§€ ì•ŠëŠ”ë‹¤.
    - ë¦¬í„´ê°’: ìƒì„±ëœ chunk ê°œìˆ˜
    """

    # 1) ì›ë³¸ íŒŒì¼ ë°”ì´íŠ¸ í™•ë³´ (ì—…ë¡œë“œì—ì„œ ë„˜ê²¨ì£¼ë©´ S3 ì™•ë³µì„ ì¤„ì¼ ìˆ˜ ìˆìŒ)
    if pdf_bytes is None:
        pdf_bytes = get_pdf_bytes(s3_key)

    if not pdf_bytes or len(pdf_bytes) == 0:
        # ìƒí™©ì— ë”°ë¼ logë§Œ ì°ê³  ë„˜ê¸¸ì§€, ì—ëŸ¬ë¥¼ ë˜ì§ˆì§€ ì •ì±… ê²°ì • ê°€ëŠ¥
        raise ValueError(f"index_document: empty file for doc_id={doc_id}")

    # 2) í˜ì´ì§€ ë‹¨ìœ„ í…ìŠ¤íŠ¸ ì¶”ì¶œ (PDF / DOCX / PPTX / TXT / MD ìë™ íŒë³„)
    pages = extract_text_pages(pdf_bytes)

    # 3) í˜ì´ì§€ â†’ ì²­í¬ ëª©ë¡ìœ¼ë¡œ ë³€í™˜
    #    chunk_pagesëŠ” [{"page": int, "text": "..."} ...] í˜•íƒœë¥¼ ë°˜í™˜í•œë‹¤ê³  ê°€ì •
    chunks = chunk_pages(pages)

    if not chunks:
        # ë¹ˆ ë¬¸ì„œë©´ ì²­í¬ë§Œ ì‚­ì œí•˜ê³  0 ë°˜í™˜
        db.query(Chunk).filter(Chunk.document_id == doc_id).delete()
        db.commit()
        return 0

    # 4) ì²­í¬ í…ìŠ¤íŠ¸ ì„ë² ë”©
    texts = [c["text"] for c in chunks]
    embs  = embed_texts(texts)

    # 5) ğŸ”¥ ê¸°ì¡´ ì²­í¬ ì „ë¶€ ì‚­ì œ â†’ ì¬ì¸ë±ìŠ¤ ì‹œì—ë„ ì¤‘ë³µ NO
    db.query(Chunk).filter(Chunk.document_id == doc_id).delete()

    # 6) ìƒˆ ì²­í¬ + ì„ë² ë”© ì €ì¥
    for c, e in zip(chunks, embs):
        db.add(
            Chunk(
                id=uuid.uuid4(),
                document_id=doc_id,
                page=c["page"],
                text=c["text"],
                embedding=e,
            )
        )

    db.commit()

    return len(chunks)
