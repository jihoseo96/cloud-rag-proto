# app/routes/documents.py
from fastapi import APIRouter, UploadFile, File, Form, Depends, HTTPException, Request
from sqlalchemy.orm import Session
from app.models.db import SessionLocal
from app.models.document import Document
from app.services.s3 import put_pdf  # TODO: ë©€í‹°í¬ë§· ë°˜ì˜í•´ì„œ ë‚˜ì¤‘ì— put_documentë¡œ ì´ë¦„ ë³€ê²½ ê³ ë ¤
from app.services.indexer import index_document
import os, uuid, hashlib

router = APIRouter(prefix="/documents", tags=["documents"])


def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()


WORKSPACE = os.getenv("WORKSPACE", "personal")


@router.post("/upload")
async def upload_document(
    request: Request,
    file: UploadFile = File(...),
    title: str = Form(...),
    db: Session = Depends(get_db),
    group_id: str | None = Form(None),
):
    """
    íŒŒì¼ ì—…ë¡œë“œ ì—”ë“œí¬ì¸íŠ¸.
    - PDF / DOCX / PPTX / TXT / MD ë“± ë°”ì´ë„ˆë¦¬ë¼ë©´ ë¬´ì—‡ì´ë“  ìˆ˜ìš©
    - S3ì—ëŠ” ì›ë³¸ ë°”ì´íŠ¸ ê·¸ëŒ€ë¡œ ì €ì¥
    - ì¸ë±ì‹± ë‹¨ê³„ì—ì„œ extract_text_pagesê°€ í¬ë§·ì„ ìë™ íŒë³„
    """
    content = await file.read()

    # ë„ˆë¬´ ì‘ì€ íŒŒì¼ ë°©ì–´ ë¡œì§ (í¬ë§· ì œí•œ X)
    if len(content) < 8:
        dbg_path = f"/tmp/orig-{uuid.uuid4()}-{file.filename}"
        with open(dbg_path, "wb") as f:
            f.write(content)
        raise HTTPException(
            status_code=400,
            detail=f"File too small: size={len(content)}, saved={dbg_path}",
        )
    file_hash = hashlib.sha256(content).hexdigest()

    existing = (
        db.query(Document)
        .filter(
            Document.workspace == WORKSPACE,
            Document.sha256 == file_hash,
        )
        .first()
    )

    if existing:
        # ğŸ” ë©±ë“±: ê°™ì€ íŒŒì¼ì´ ì´ë¯¸ ì¸ë±ì‹±ë˜ì–´ ìˆìŒ â†’ ì¬ì‚¬ìš©
        return {
            "status": "already_indexed",
            "document_id": str(existing.id),
            "s3_key": existing.s3_key_raw,
            "group_id": str(existing.group_id) if existing.group_id else None,
            "duplicate": True,
        }

    print(
        f"[upload] len(content)={len(content)}, "
        f"filename={file.filename!r}, ct={request.headers.get('content-type')}"
    )

    # S3 ì—…ë¡œë“œ(ì›ë³¸ ë°”ì´íŠ¸ ê·¸ëŒ€ë¡œ)
    # í˜„ì¬ í•¨ìˆ˜ëª…ì´ put_pdfì´ì§€ë§Œ, ì‹¤ì œë¡œëŠ” ë©€í‹°í¬ë§· ë°”ì´ë„ˆë¦¬ë¥¼ ì €ì¥í•˜ëŠ” ìš©ë„.
    # TODO: ë‚˜ì¤‘ì— s3.pyê¹Œì§€ í¬í•¨í•´ì„œ put_document(...) ë“±ìœ¼ë¡œ ë„¤ì´ë° ì •ë¦¬ ê°€ëŠ¥.
    doc_id, key = put_pdf(content, title)
    if isinstance(doc_id, str):
        doc_id = uuid.UUID(doc_id)

    # group_id íŒŒì‹± (optional)
    gid = None
    if group_id:
        try:
            gid = uuid.UUID(group_id)
        except Exception:
            raise HTTPException(status_code=422, detail="invalid group_id (must be UUID)")

    # document ë©”íƒ€ ì €ì¥
    db.add(
        Document(
            id=doc_id,
            workspace=WORKSPACE,
            s3_key_raw=key,
            title=title,
            group_id=gid,
            sha256=file_hash,
        )
    )
    db.commit()

    # ì¸ë±ì‹±ì— **ì›ë³¸ ë°”ì´íŠ¸ ê·¸ëŒ€ë¡œ ì „ë‹¬** â†’ S3 ì™•ë³µ ì œê±°
    # index_document ë‚´ë¶€ì—ì„œ extract_text_pages(...)ë¥¼ í˜¸ì¶œí•˜ê³ ,
    # ê·¸ í•¨ìˆ˜ê°€ PDF / DOCX / PPTX / TXT / MDë¥¼ ìë™ íŒë³„í•´ì„œ í…ìŠ¤íŠ¸ë¥¼ ë½‘ëŠ”ë‹¤.
    #
    # í˜„ì¬ ì¸ì ì´ë¦„ì´ pdf_bytesì§€ë§Œ, ì˜ë¯¸ìƒ "file_bytes" ì—­í• ì„ í•œë‹¤ëŠ” ì ì„ ê¸°ì–µ.
    # TODO: ì¶”í›„ indexer.py ìˆ˜ì • ì‹œ pdf_bytes â†’ file_bytes ë“±ìœ¼ë¡œ ì´ë¦„ì„ ì •ë¦¬í•´ë„ ë¨.
    index_document(db, doc_id, key, title, pdf_bytes=content)

    # FastAPIê°€ UUIDë¥¼ ìë™ ì§ë ¬í™”í•˜ì§€ë§Œ, í™•ì‹¤íˆ í•˜ë ¤ë©´ str(...)ë¡œ ë°˜í™˜
    return {
        "status": "indexed",
        "document_id": str(doc_id),
        "s3_key": key,
        "group_id": str(gid) if gid else None,
        "duplicate": False,
    }
